#+TITLE: Modeling The Computational Universe
#+SUBTITLE: Protoverse: Computational Model
#+DATE: <2024-09-27 Fri>
#+LANGUAGE: en
#+DESCRIPTION: Creating a synthetic universe from scratch
#+KEYWORDS: philosophical modeling, computational metaphysics, computational philosophy, process philosophy, artificial universe
#+HTML_HEAD_EXTRA: <link rel="canonical" href="https://monkeyjunglejuice.github.io/blog/model.protoverse.project.html">
#+SETUPFILE: ../static/setup.org
#+PROPERTY: header-args+ :eval no-export
#+OPTIONS:

#+ATTR_HTML: :class pager
#+begin_nav
This is part of the Protoverse project:
- [[file:introduction.protoverse.project.org][Introduction]]
- [[file:metaphysics.protoverse.project.org][Metaphysics]]
- [[file:engineering.protoverse.project.org][Technical Considerations]]
- [[file:resources.protoverse.project.org][Resources]]
- *[[file:model.protoverse.project.org][Computational Model]]*
- [[file:ethics.protoverse.project.org][Ethical Guidelines]]
#+end_nav

#+begin_message
NOT STARTED YET -- I'm going to work on the model after the metaphysical framework is done. If you would like to ponder ideas, I'll be glad for your input. You will find the [[https://github.com/monkeyjunglejuice/protoverse][source code on Github]]
#+end_message

#+TOC: headlines 3

* Synchronization / Desynchronization

One of the worries and challenges when it comes to concurrent and/or parallel computation is the synchronization of outcomes. I read quite often about simulations progressing in "ticks" -- "rendering the world" in discrete steps. I don't know if that is really common practice or just in toy-like simulations and cellular automata, but this idea has to be abandoned.

Why? Well first, the Protoverse isn't supposed to be a "simulation" to begin with, but the instatiation of an abstract model. It's not going to simulate /something else/ -- but will be "the real thing" itself.

And if we're being honest (and assume that relativity is a thing), then we must acknowledge there's no real synchronization in our universe either -- it just an illusion of our daily experience (low-speed local human experience plus our limited spatial scale). Just a simple example: There is no "at this moment" on the moon while you're on Earth. The striving, longing for synchronization is real, no doubt -- but can never be reached. Maybe that nurtures our obsession with synchronicity.

Ok to sum it up: global time doesn't exist in reality and wouldn't make sense in the Protoverse either; it violates the process-relational Protoverse metaphysics (no background time, no background space -- these are emergent phenomena), and regarding efficient computation, synchronous progression is probably the worst possible decision, as it kills parallelization and scaling. Maybe the universe is so efficient because it's inherently asynchronous.

Ok, that out of the way -- what does it mean for our model?
- Only partial orders, not total orders
- Causality becomes the foundation of consistency
- "Synchronize" only what actually interacts
- Everything else remains decoupled and can run in parallel

* The Abstract Process

/This is about [[file:metaphysics.protoverse.project.org][Process (metaphysics]]); not to confuse with process or thread (computation)./

The Process abstraction is prior, and it's the only truly scale-invariant principle. Processes do not exist /within/ an environment or within space or time -- instead, the relational dynamics of processes bring about perceived structures and dimensions, as they continuously /become/ their environment, actively co-creating (resp. co-evolving) the substrate they are operating in.

** Interaction Dynamics

*** Ideas for the Initial Epistemological Scope of Primitive Processes

As Processes evolve and emerge higher-order Processes, it's reasonable to assume that the interactions could become more complex, transcending this initial scope. Some crude ideas:

**** 1. Idea: Lexical Scope and Black Boxes
There are no isolated Processes ("closed systems"), but a Process =P= cannot fully access the state of an arbitrary Process =Q= it interacts with. The arbitrary Process =Q= can initially only be understood in terms of a blackbox and successively modelling thereof, and interacted with according to the interfaces the Process =Q= exposes. Interfaces may adapt through ongoing interaction.

The interaction =P âˆ§ Q= leads to an aggregate Processes (higher-order Process) =PQ=.

This interaction between both might also create or alter sub-Processes =Px= and =Qx= within the boundaries of =P'= and =Q'=. The sub-processes =P'.X= and =Q'.X= can be fully accessed only by their respective super-Processes, while they cannot fully access the state of their super-Processes =P'= and =Q'= (same as the initial situation); hence =P.X= and =Q.X= need to reseort to black box analysis. While doing so, they have to create an inner model =P.X.Y= and =Q.X.Y=, and that would lead to an infinite regress, but not if each inner, newly spawned sub-Process is always a primitive Process.

However, it is unclear yet how far the access to newly initiated sub-Processes =P.X= reaches, and under what circumstances, and if or to which extent the super-Process =P'= gradually loose access to these newly emerged child Processes, e.g. =P.X=, =P.X.Z=, etc.

Maybe the access decays, the more interactions the evolved Processes =P'= and =Q'= experience (more relations piling up in their interaction logs) without further involvement of the child Processes =Xn=? Also, access from parent Processes to child Process may decay the more independent interactions the child Processes experience; the "further away" they get?

**** 2. Idea:
.....
